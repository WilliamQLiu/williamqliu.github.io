---
layout: post
title: MySQL
---

## {{ page.title }}

- - - -

**Summary**

__SQL (Structured Query Language)__ is the standard language for communicating with relational database management systems.  There's a few variations including Microsoft's SQL Server, MySQL, PostgreSQL, SQLite.  Below instructions are with MySQL.  We'll setup a MySQL server, then use a client to connect to the server and query for data.

## Installation

### Mac Install

On a mac, use homebrew to install mysql using `$brew install mysql` to install the MySQL as a server.  For a GUI client, you can download MySQL Workbench, which will allow you to visually see the data with a GUI (as opposed to only command line).

### Linux (Ubuntu) Install

For Ubuntu, use your package manager to install `sudo apt-get install
mysql-server` and your workbench `sudo apt-get install
mysql-workbench-community` 

Then setup with `sudo /usr/bin/mysql_secure_installation`, where you can setup
root password and other configurations.

### Terminal Client

Instead of the regular 'mysql' terminal client, I actually like `mycli`: https://github.com/dbcli/mycli/

For the MySQL Prompt in mycli, I changed it to:

	# MySQL prompt
	# \t - Product type (Percona, MySQL, Mariadb)
	# \u - Username
	# \h - Hostname of the server
	# \d - Database name
	# \n - Newline
	#prompt = '\t \u@\h:\d> '
	prompt ="(\u@\h) [\d]> "

## Commands

* Run secure installation script `sudo /usr/bin/mysql_secure_installation`
* Login with `mysql -uroot -psome_password`

### Useful MySQL commands (Start, Stop Server)

    $systemctl status mysql  # check status of server
    $systemctl start mysql  # start the server
    $systemctl stop mysql   # stop the server
    $systemctl help mysql  # get help commands

### Run a text file (containing sql scripts) from command line

    $mysql < myscript.sql

### Switching to mysql shell

    $mysql  # enters into the shell from bash
    $mysql -u root -p  # enters into the shell as root user and prompts for
    password
    mysql>  # This is what you'll see when in shell

## MySQL Commands

### Create, Drop, and Use a Database
    mysql> DROP DATABASE IF EXISTS my_database_name;
    mysql> CREATE DATABASE my_database_name;
    mysql> USE my_database_name;

### Show list of users

To show the list of users, we want to look at the mysql database.

    mysql> use mysql;
    mysql> show tables;

We're interested in the **user** table on the **mysql** database.
    
    mysql> describe mysql.user;

For older versions of MySQL (below 5.7), you might want to look at these fields:
    mysql> select host, user, password from mysql.user;

For more recent version of MySQL (5.7+), you might want to look at these fields:
    mysql> select host, user, authentication_string from mysql.user;

#### Update user password

To update the user password:

    mysql> update user set authentication_string=password('1111') where
user = 'root';

#### Create user

#### Grant privileges

To grant all privileges to a user on host 'localhost' with a database called 'db_test' do:

    GRANT ALL ON db_test.* to 'tester'@'localhost';

To update privileges

    FLUSH PRIVILEGES;

### Status of current database, user 

    mysql> status   # Shows current database, current user
    --------------
    mysql  Ver 14.14 Distrib 5.7.18, for Linux (x86_64) using  EditLine wrapper

    Connection id:		10
    Current database:	
    Current user:		root@localhost
    SSL:			Not in use
    Current pager:		stdout
    Using outfile:		''
    Using delimiter:	;
    Server version:		5.7.18-0ubuntu0.16.04.1 (Ubuntu)
    Protocol version:	10
    Connection:		Localhost via UNIX socket
    Server characterset:	latin1
    Db     characterset:	latin1
    Client characterset:	utf8
    Conn.  characterset:	utf8
    UNIX socket:		/var/run/mysqld/mysqld.sock
    Uptime:			13 min 24 sec

    Threads: 1  Questions: 10  Slow queries: 0  Opens: 115  Flush tables: 1  Open tables: 34  Queries per second avg: 0.012

### Show databases

List all the available databases

    mysql> show databases;
    +--------------------+
    | Database           |
    +--------------------+
    | information_schema |
    | mysql              |
    | performance_schema |
    | sys                |
    | willdb             |
    +--------------------+ 

### Show tables

List all the available tables in a database

    mysql> use willdb;
    mysql> show tables;

    mysql> show tables;
    +------------------+
    | Tables_in_willdb |
    +------------------+
    | iris             |
    +------------------+

### describe tables

See the table structure

    mysql> describe iris;
    +-------------+-------------+------+-----+---------+-------+
    | Field       | Type        | Null | Key | Default | Extra |
    +-------------+-------------+------+-----+---------+-------+
    | sepallength | float       | YES  |     | NULL    |       |
    | sepalwidth  | float       | YES  |     | NULL    |       |
    | petallength | float       | YES  |     | NULL    |       |
    | petalwidth  | float       | YES  |     | NULL    |       |
    | class       | varchar(30) | YES  |     | NULL    |       |
    +-------------+-------------+------+-----+---------+-------+
    5 rows in set (0.00 sec)


### see indexes on a table

Indexes in general help speed up database reads (e.g. search) and slows down database writes.
If you index a column, you create ordering (e.g. say alphabetically) through an index. Instead of searching
through all n rows, you might have a binary search w/ log-n index entries.

List all the indexes on a table

    mysql> show index from iris;

TODO: Read up more on the topics of 'lock contention', 'deadlock' caused by indexes'

### show triggers

Show database triggers:

	mysql> show triggers like '%something%';

## Explain

`explain` is often used with complex queries, optimizing queries, and __indexes__. Put explain in front of a query
that has 'select', 'update', 'delete', 'insert', 'replace', 'update'

    mysql> explain select * from my_db.my_table;
    +------+---------------+-----------------+--------+-----------------+--------+-----------+--------+--------+---------+
    | id   | select_type   | table           | type   | possible_keys   | key    | key_len   | ref    | rows   | Extra   |
    |------+---------------+-----------------+--------+-----------------+--------+-----------+--------+--------+---------|
    | 1    | SIMPLE        | my_table        | ALL    | <null>          | <null> | <null>    | <null> | 343848 |         |
    +------+---------------+-----------------+--------+-----------------+--------+-----------+--------+--------+---------+

Here's an example that uses an index:

    explain select property_id, mls_id from my_db.my_table;
    +------+---------------+-----------------+--------+-----------------+---------+-----------+--------+--------+-------------+
    | id   | select_type   | table           | type   | possible_keys   | key     | key_len   | ref    | rows   | Extra       |
    |------+---------------+-----------------+--------+-----------------+---------+-----------+--------+--------+-------------|
    | 1    | SIMPLE        | my_table        | index  | <null>          | ix_cpid | 5         | <null> | 343848 | Using index |
    +------+---------------+-----------------+--------+-----------------+---------+-----------+--------+--------+-------------+

Here's an example with a join:

	explain select count(*), t1.loc_city from idx.mlslv4_master t1 join
		    enterprise.community t2 where t1.loc_city = t2.name and t2.owner_id=44 group by t1.loc_city;
	+------+---------------+---------+--------+-----------------+-------------+-----------+--------------------+--------+---------------------------------+
	| id   | select_type   | table   | type   | possible_keys   | key| key_len   | ref    | rows               | Extra  |                                 |
	|------+---------------+---------+--------+-----------------+-------------+-----------+--------------------+--------+---------------------------------|
	| 1    | SIMPLE        | t2      | ref    | company_id      | company_id 	 | 4      | const              | 179    | Using temporary; Using filesort |
	| 1    | SIMPLE        | t1      | ref    | ix_loc_city     | ix_loc_city 	 | 33	  | enterprise.t2.name | 10     | Using where; Using index        |
	+------+---------------+---------+--------+-----------------+-------------+-----------+--------------------+--------+---------------------------------+


## Loading Data

Say we want to load the iris dataset.  We do a curl to get the dataset, then run the below sql query.

    curl http://mlr.cs.umass.edu/ml/machine-learning-databases/iris/iris.data > iris.csv


|sepallength|sepalwidth|petallength|petalwidth|class      |
|-----------|----------|-----------|----------|-----------|
|5.1        |3.5       |1.4        |0.2       |Iris-setosa|
|4.9        |3         |1.4        |0.2       |Iris-setosa|
|4.7        |3.2       |1.3        |0.2       |Iris-setosa|

    LOAD DATA LOCAL 
    
    #EDIT THIS PATH:
    INFILE "/Users/williamliu/Desktop/iris.csv"   
    
    INTO TABLE sampdb.iris  #db sampdb, table iris
    
    FIELDS
        TERMINATED BY ',' 
        #ENCLOSED BY '"' 
    
    LINES
       TERMINATED BY '\n'
    #IGNORE 1 LINES;

## Create Table

    create table iris(
    sepallength float,
    sepalwidth float,
    petallength float,
    petalwidth float,
    class nvarchar(30)
    );

## Queries

### Basic Format of SQL Queries

Assuming data (say mytable from mydatabase) looks like:

    # last_name, first_name, suffix, city, state, birth, death
    Adams, John, , Braintree, MA, 1735-10-30, 1826-07-04
    Adams, John Quincy, , Braintree, MA, 1767-07-11, 1848-02-23
    Arthur, Chester A., , Fairfield, VT, 1829-10-05, 1886-11-18
    Buchanan, James, , Mercersburg, PA, 1791-04-23, 1868-06-01
    Bush, George H.W., , Milton, MA, 1924-06-12, 

We can do the following query:

    SELECT last_name, first_name, state
    FROM mydatabase.mytable;

*  a database holds a lot of tables
*  a table holds lots of rows and columns of data
*  a record is a particular instance of a row and column

### ROW NUMBER

To get a returning count of what the row number is, do this.  Note that you can set variables and return them in the results.

    SET @n=0;
    SELECT @n := @n+1 AS 'row_num', sepallength FROM sampdb.iris;

### COUNT

    SELECT COUNT(*) FROM sampdb.president
    SELECT COUNT(first_name), COUNT(death) FROM sampdb.president  # Returns 42 and 38
    SELECT COUNT(DISTINCT state, first_name) FROM sampdb.president

*  Counts the not NULL values passed into it
*  This is an 'aggregating' function - takes a set of records or values and performs calculations on that set
*  For `Distinct`, we get 42 instead of 43 total presidents, means one duplicate state and first_name combo
*  Can also Subset and Count the data

### Other Functions (AVG, SUM, MIN, MAX)

    SELECT AVG(death) FROM sampdb.president
    SELECT SUM(age) FROM sampdb.president
    SELECT MIN(age) FROM sampdb.president
    SELECT MAX(age) FROM sampdb.president

### Functions (AS, DATEDIFF, CONCAT, etc.)

    SELECT ... score * 2 AS doubled_score
    SELECT ... DATEDIFF(death, birth)
    SELECT ... CONCAT(first_name, ' ', last_name)
    SELECT ... UNIQUE(last_name, middle_name, first_name)

*  Can create an alias with `AS` (required for subqueries)
*  Can run functions (e.g. `CONCAT` combines strings into one, `DATEDIFF` gets difference in days)
*  Can get unique values using `UNIQUE`

### NULL Values and Functions

*  __NULL__ values represent missing or unknown data (not the same as the value 0).
*  To test for _NULL_, do __IS NULL__ or __IS NOT NULL__.
    -  __IS NULL__ checks if the value is null.  For example, `SELECT LastName, FirstName FROM Persons WHERE LastName IS NULL`
    -  __IS NOT NULL__ checks if the value is not null.  For example, `SELECT LastName, FirstName FROM Persons WHERE LastName IS NOT NULL`
*  There are functions __ISNULL(), NVL(), IFNULL(), and COALESCE()__ that specify how we want to treat a _NULL_ value
    -  For MySQL, _IFNULL()_ tells us how to treat a _NULL_ value (in this case, replacing it with 0): `SELECT UnitPrice*(UnitsInStock+IFNULL(UnitsOnOrder,0)) FROM Products`

### WHERE

    SELECT COUNT(first_name) FROM sampdb.president WHERE last_name="Adams" 

*  Filters (before `GROUP BY`)
*  Can pass in lists (using `IN`) or tuples
    -  Filter by list: ... `WHERE state IN ('MA', 'VA')`
    -  Filter by tuple: ... `WHERE (last_name, state) IN ('Adams', 'MA')`

### GROUP BY

    SELECT state, COUNT(*) FROM sampdb.president GROUP BY state ORDER BY state

*  GROUP BY is a subset; divides records by unique tuples

### GROUP BY using WHERE and HAVING

    SELECT state, COUNT(*) FROM sampdb.president
       WHERE birth <= '1900-01-01'
       GROUP BY state
       HAVING COUNT(*) >=2
       ORDER BY COUNT(*);

Sample Output:
    
    state, count(*)
       MA, 2
       VT, 2
       NC, 2
       NY, 4
       OH, 7
       VA, 8

*  WHERE filters before the GROUP BY
*  HAVING filters after the GROUP BY

### Subqueries
*  Subqueries is a query inside another query
*  Usually this means an __outer query__ and an __inner query__
   `SELECT name FROM city WHERE pincode IN (SELECT pincode FROM pin WHERE zone = 'west')`
   -  __outer query__ is `SELECT name FROM city WHERE pincode IN ...`
   -  __inner query__ is `SELECT pincode FROM pin WHERE zone = 'west'`
*  Returned table has to have the fields and row expected of it by the calling query
*  Alias (`AS`) is required for subqueries
*  Two varieties of subqueries (__correlated__ and __non-correlated__)
    
    -  __Non-correlated subquery__ means that the _inner query_ doesn't depend on the _outer query_ and can run as a stand alone query
    
      *  `SELECT company FROM stock WHERE listed_on_exchange = (SELECT ric FROM market WHERE country='japan')`
        - The _inner query_ executes first, then the _outer query_.
        - _non-correlated subqueries_ usually use `IN` or `NOT IN`

    -  __Correlated subquery__ means that the _inner query_ depends on the _outer query_
    
      *  `SELECT student_id, score FROM sampdb.score AS scr WHERE event_id = 3 AND score > ( SELECT AVG(score) FROM sampdb.score WHERE event_id = scr.event_id GROUP BY event_id) )`
        - Requires use of alias (`AS`)
        - The _outer query_ executes first, then the _inner query_; this is because the _inner query_ depends on the output of the _outer query_
        - These queries are slower than _non-correlated queries_ (think about doing a _join_ instead)
        - _correlated subqueries_ usually use `EXISTS` or `NOT EXISTS`

### EXISTS

*  The __EXISTS__ and __NOT EXISTS__ conditions are used with a subquery (usually the _correlated subquery_).  Condition is met if the subquery returns at least one row.  It can be used with _SELECT, INSERT, UPDATE, or DELETE_ statements.
*  `SELECT * FROM mysuppliers WHERE NOT EXISTS (SELECT * FROM myorders WHERE mysuppliers.supplier_id = myorders.order_id);`
*  Note that these are very inefficient since the sub-query is re-run for every single row so use only if no other solution


### JOINS
Used to combine rows from two or more tables.  Types of joins include:

*  __INNER JOIN__ selects all rows from both tables that have a match
    - `SELECT column_name(s) FROM table1 INNER JOIN table2 ON table1.column_name=table2.column_name;`
*  __LEFT JOIN__ selects all rows from the left table (table1) and matching rows on the right table (table2)
    - `SELECT column_name(s) FROM table1 LEFT JOIN table2 ON table1.column_name=table2.column_name;`
*  __RIGHT JOIN__ selects all rows from the right table (table2) and matching rows on the left table (table1)
    - `SELECT column_name(s) FROM table1 RIGHT JOIN table2 ON table1.column_name=table2.column_name;`
*  __FULL JOIN__ selects all rows from the left table (table1) and all rows on the right table (table2)
    - `SELECT column_name(s) FROM table1 FULL OUTER JOIN table2 ON table1.column_name=table2.column_name;`
*  __UNION and UNION ALL__ combines the result of two or more SELECT statements (with each statement having the same number of columns, data types, and order).  _UNION_ selects distinct values only.  _UNION ALL_ allows duplicates.
    -  `SELECT column_name(s) FROM table1 UNION SELECT column_name(s) FROM table2`
    -  `SELECT column_name(s) FROM table1 UNION ALL SELECT column_name(s) FROM table2`

### Primary Key (PK) and Foreign Key (FK)
*  A __primary key__ constraint uniquiely identifies each record in a database table.  These values must be unique, cannot contain NULL values, and each table can only have one primary key.  Note that you can have multiple column values that make up the primary key (e.g. P_ID, LastName, SSN).
    -  Add a _primary key_ to a table with a single column (e.g. P_ID) as the constraint: `ALTER TABLE MyTable ADD PRIMARY KEY (P_ID)`
    -  Add a _primary key_ to a table with multiple columns (e.g. P_ID, LastName) as the constraint: `ALTER TABLE MyTable ADD PRIMARY KEY(P_ID, LastName)`
    -  Remove a _primary key_: `ALTER TABLE MyTable DROP PRIMARY KEY`
*  A __foreign key__ constraint in one table is just a _primary key_ in another table.
    -  Add a _foreign key_ on a single column as the constraint: `ALTER TABLE MyTable ADD FOREIGN KEY (P_ID) REFERENCES OtherTable(P_ID)`
    -  Add a _foreign key_ on multiple columns (e.g. P_ID) as the constraint: `ALTER TABLE MyTable ADD CONSTRAINT my_fk FOREIGN KEY (P_ID) REFERENCES OtherTable(P_ID)`
    -  Remove a _foreign key_ with: `ALTER TABLE MyTable DROP FOREIGN KEY my_fk`

### DROP and TRUNCATE
*  To delete an entire database, be extra sure you want to and can spell correctly, then do: `DROP DATABASE MyDatabase`.  This deletes everything in the database.
*  To delete an entire table (including the table itself), be extra sure you want to and can spell correctly, then do: `DROP TABLE MyTable`
*  To delete the data inside an entire table, do: `TRUNCATE TABLE MyTable`

### ALTER
*  To add, delete, or modify columns in an existing table, use __ALTER__.
*  To add a column in a table, use: `ALTER TABLE MyTable MODIFY COLUMN MyColumn <datatype>`
*  To delete a column in a table, use: `ALTER TABLE MyTable DROP COLUMN MyColumn`
*  To modify a column in a table, use: `ALTER TABLE MyTable MODIFY COLUMN MyColumn <datatype>`

### INSERT
*  To insert data by field: `INSERT INTO MyDatabase.MyTable SET ThisField = ThisData`
*  To insert data by row: `INSERT INTO MyDatabase.MyTable VALUES ('field1', 'field2', 'field3'`

### UPDATE
    UPDATE MyDatabase.MyTable SET ThisField = ThisData

### DELETE
    DELETE FROM MyDatabase.MyTable  # Careful, no criteria deletes the entire database!

### IF
    IF(2>1, 'OK', 'NOT)

### CASE
    CASE
        WHEN 2 > 1
            THEN 'OK'
        WHEN 1==1
            THEN 'YEP'
        ELSE
            'NOT OK'
    END

You can combine all of the above into something like this (Note: From SQL Server):
    
    SELECT IVRName, 
    SUM(CASE WHEN Disconnection in ('Answer') THEN 1 END) AS Answered, 
    SUM(CASE WHEN Disconnection in ('Abandon') THEN 1 END) AS Abandoned
    FROM LifeNetDW.dbo.QueueMetrics
    WHERE CallTime > '2015-1-31' AND IVRName IS NOT NULL
    GROUP BY IVRName

## Indexing

An index is a copy of selected columns from a table that can be searched efficiently (with a
link to the complete row of data it was copied from).

*  Makes processing things much faster
*  An index is a pre-ordered sort of a particular field
*  Done and stored by the database server
*  Indexing has storage and performance costs
*  For every index on a table, the database must reorder the index for a new entry
*  Each index takes up space in storage and memory
*  Do 'profiling' to see where things are slow
*  To create an index, do: `CREATE INDEX MyIndex on MyTable (colToIndex)`
*  To create an index on a combination of volumns, do: `CREATE INDEX MyIndex on MyTable(colToIndex1, colToIndex2, colToIndex3)`
*  To drop an index, do: `ALTER TABLE MyTable DROP INDEX MyIndex`

### Binary Logging

Before we get into lock contention, let's bring up how __binary logging__ works. The binary log contains
'events' that describe database changes (e.g. table create, updates to table data). This log is used on the master
server to send events to slave servers.

Data recovery operations also use the binary log. Statements like SELECT and SHOW aren't included in the binary log.
To enable the binary log, start the server with `--log-bin[=base_name]` where the default `base_name` is the name
of the host machine followed by `-bin`.

### Lock Contention

This is on the 'user' table with a PK on `user_id`

    user_id(pk) | name   | status
    1           | Ronald | 0
    100         | Messi  | 0
    10000000    | Raul   | 9


Read about binary logging first, then read below about lock contention. An example of lock contention is where:

* Session/Query 1: `DELETE FROM user WHERE status=9` and it takes a long time to scan and delete
    - Query OK, 1000 rows affected (14 sec)
* Session/Query 2: `UPDATE user SET status=9 where user_id=100`
    - Query OK, 1 row affected (12 sec)
    - Rows matched: 1 Changed: 1 Warnings: 0

Why did Query 2 get blocked by Query 1? Let's think about the scenario if Query 1 does not block Query 2:

* Query 2 will finish before Query 1
* Query 1 already checked row: `user_id=100`
* The row with Messi was not deleted because status == 0 
* The final result of the row is that row 100 exists with status=9
* This means that data consistency is broken because the binary log looks like:
    - `UPDATE user SET status=9 WHERE user_id=100;`
    - `DELETE FROM user WHERE status=9;`
* Any slave databases with `user_id=100` will not exist, but will exist on master

So basically, the table `user` needs to be locked because any following operations on that same table will cause
data inconsistencies for binary logging (thus issues w/ say data replication to slaves).

To solve this we can use __next-key locking__, where we lock not just the 'modified' rows, but also 'scanned' rows.
The disadvtange is low concurrency.

#### If column is indexed

If the status column is indexed, then Queries 1 and 2 can run in parallel (to improve concurrency).

### Deadlock caused by indexes

    user_id(pk) | name   | status
    1           | Ronald | 0
    2           | John   | 1 
    10000000    | Raul   | 9


### Covering index and range scan / LIMIT

### Covering index and long text/blob

### Sorting, indexing and query execution plans


## Other

### Schemas
*  Command: SHOW DATABASES;
    -  Shows all databases available on the server
*  Command: SHOW TABLES IN books;
    - Shows all tables available in a particular database
*  Command: DESCRIBE books.authors;
    - Shows columns, data types, keys, in a particular table
*  Command: SHOW CREATE TABLE books.authors\G;
    - Shows the command for creating a table

### Normalization (Nth normal form)

*  Principles of Modeling Data 'norms'
*  Rules for making sure data is where we expect it and that it isn't duplicated
*  __First Normal Form (1NF)__
    - Data should be atomic (i.e. values should not be combined)
    - E.g. George Washington shouldn't be a value (because it combines first and last name)
    - No repeating columns
    - E.g. Columns like Author1, Author2, Author3
*  __Second Normal Form (2NF)__
    - No 'partial dependencies'
    - Cannot determine a nonkey column value with only a portion of the primary key
    - Basically, unnecessary duplication
*  __Third Normal Form (3NF)__
    - Second Normal Form plus no nonkey column depends on the value of another nonkey column
    - Values are driven by the primary key fields; these values should be removed to a table of their own

## Moving Files

If you need to move data across servers, you might have to do some extra work. If you're on the database server,
you have access to `OUTFILE` and `INFILE`, so you can dump data out or into say a csv file or a .sql file.

### mysqldump

You can use `mysqldump` on the command line like this (login, get data from a database and table with a where clause)

	mysqldump -t -u myusername -p mypassword -h myhostname --port 3306 mydatabasename mytablename --where="status='Sure'"

You can also run `mysql` on the command line like so (run a sql query, replace tabs with ',', then dump to a csv file
	
	mysql -u myusername -p mypassword -h myhostname mydatabasename mytablename -e "SELECT * FROM some_table" | tr '\t' , > myData.csv

Some of these commands assume you're on the same server as the database server, which you probably won't be. Use `LOCAL INFILE` instead if you want to upload a file to a remote server

	mysql -u myusername -p mypassword -h myhostname --database mydatabasename -e "LOAD DATA LOCAL INFILE '/home/will/myData.csv' INTO TABLE sometable LINES TERMINATED BY '\n' IGNORE 1 LINES"

Sometimes it helps to dump some data from another server into the server you need,  then do a quick join and update.

	update some_database.some_table a
		join some_database.some_other_table b on a.id = b.id
	set a.some_status=0

