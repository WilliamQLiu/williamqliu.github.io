---
layout: post
title: Ansible
---

## {{ page.title }}


- - - -

# Summary

Notes on Devops systems, including VirtualBox, Vagrant, Ansible, Docker. Installation instructions for Mac.

## Vagrant and VirtualBox

Vagrant helps create and configure lightweight, reproducible, and portable development environments.

VirtualBox is separate, but often goes with Vagrant because its virtualization for hardware (usually for servers).

### Setup Vagrant and Virtualbox

Install with Homebrew's Cask.

* `brew cask install virtualbox`
* `brew cask install vagrant`
* `brew cask install vagrant-manager`

### Vagrant Useful Commands

Useful commands include:

`vagrant init centos/7` to initialize vagrant with centos/7 box, with boxes that can be found at hashicorp
`vagrant up` to bring vagrant up and running
`vagrant box add centos/7` to add a box
`vagrant ssh` to ssh into the machine
`vagrant reload --provision` to provision the server

### Vagrantfile

Wherever you did the init with Vagrant is your root directory. You should see a hidden `.vagrant` directory and a Vagrantfile.

You can configure the Vagrantfile, e.g. setup the provisioning like:

    Vagrant.configure("2") do |config|
      config.vm.provision "ansible" do |ansible|
        ansible.playbook = "playbook.yml"
      end
    end

## Ansible

**Ansible** helps automate provisioning, configuration management, and application deployment using an agentless architecture.

Ansible does this by setting up **playbooks** that contain **plays**, **tasks** and **handlers**. We can also assign **roles** and **variables**.

###Installing Ansible

Install Ansible with `pip install ansible` (will also install other libraries).

### Inventory File

Inventory Files are just lists of hosts. Check what hosts are available with `ansible all -m ping`.

* Depending on your local setup, the hosts file might be in `/etc/ansible/hosts` or `/usr/local/etc/ansible/hosts`
* You can specify where to look for the hosts with an environment variable: `export ANSIBLE_INVENTORY=~/ansible_hosts`

Here's a sample inventory file (has an INI-like format):

    mail.jobwaffle.com:5309

    [webservers]
    foo.jobwaffle.com
    bar.jobwaffle.com

    [dbservers]
    db1.jobwaffle.com
    db2.jobwaffle.com 

### Run ad-hoc Ansible commands

With just an inventory file, you can run one off ansible commands directly like:

* `ansible all -a /bin/date`
* `ansible all -m ping`

### Playbooks

**Playbooks** declare configurations, orchestrate steps across machines, and launch tasks (asynchronously and synchronously).

* Playbooks are setup in YAML format with one or more **plays** per playbook.
* The goal is to map a group of **hosts** to some well defined roles, represented as **tasks**.
* Run playbooks with `ansible-playbook site.yml` where **site.yml** is the playbook.

### Hosts and Users

**Hosts** determine which machines to target (e.g. dbservers, webservers). This is marked by `hosts: something`
**Roles** (aka **Users**) determine which role or user to run as executing a task (e.g. root). This is marked by say `remote_user: root`

Example Usage:

    ---
    - hosts: webservers
      remote_user: root

### Tasks

Each play contains a list of tasks that are executed in order, one at a time.

* Tasks will be run if matched by **hosts**
* Each task should idempotent (i.e. run multiple times and no effect if already ran)
* Each task should have a **name** that describes what the script is doing

### Handlers

Playbooks have a basic event system that can respond to change only once; this system is called **handlers** and they are called by other plays. Handlers are triggered by **tasks**

An example handler might be to restart httpd:

    handlers:
    - name: restart apache
      service: name=httpd state=restarted

## Docker

Docker is an open platform to build, ship, and run distributed applications. Docker consists of Docker Engine, a lightweight runtime and packaging tool that is made up of:

* A daemon (aka server); a server process that manages all the containers
* Clients act as a remote control for the daemon. Clients talk to the docker server/daemon
* Images are the building blocks of Docker, think of it like the source code for your containers. Images are built by adding a file, running a command, opening a port. Example images include Nginx or Postgresql database.
* Containers are launched from images and can contain one or more running processes. A Docker container is:
    * An image format (think of this as the cargo)
    * A set of standard operations (think of it as what it can do with the cargo, e.g. create, start, stop, restart, destroy)
    * An execution environment (think of it as where to ship your container; can build on laptop, deploy to EC2 instance)

The goal of Docker is to enable apps to be quickly assembled from components and eliminates the friction between different environments (dev, QA, production).

### Containers with microservices

Docker Containers are natural for microservices.
    * Simple to Model
    * Available in any app, any language
    * Image is the version
    * Test and deploy from same artifact
    * Stateless servers decrease change risk

### Scheduling Containers

Scheduling a single resource is easy, just run a single container on laptop.
Scheduling a cluster of containers is difficult.
    * How do I roll out new versions of my software?
    * What happens if one of my machines dies?

## AWS ECS

Amazon EC2 Container Service (ECS) is a container management service. You can
use ECS to schedule the placement of containers across your cluster. You can
integrate your own scheduler or a third-party scheduler.

### Cluster Management: Resource Management

A resource manager is responsible for keeping track of resources (memory, cpu,
storage) on a cluster at any given time. E.g. 3 EC2 instances across
2 availability zones, each running Docker and has tasks running on containers.

### Cluster Management: Scheduling

Scheduler is responsible for scheduling tasks for execution. Say X node does
Y task based on resources above (memory, cpu, storage). Scheduling requests the
resource and confirms request done. Scheduler knows if task is alive or dead (if dead, then
reschedule).

AWS handles resource management and scheduling with the **Cluster Management
Engine**. You can segment your cluster based on say dev, test, production.

AWS has an **Agent Communication Service** that talks with an **ECS Agent**
(installed on each ECS container).

AWS has a Key/Value Store to handle state so that we have concurrency control.

You can access a lot of this through an API.

## Setup Docker

Setup for a Mac.

### Docker

* Docker Engine, can check with `docker --version`
* Compose, can check with `docker-compose --version`
* Machine, can check with `docker-machine --version`

## Docker General Commands

* `docker` to get a list of docker commands
* `docker info` to tell you about the current setup

## Docker Linking Containers

You can create a secure tunnel between containers so that they don't have to expose any ports externally. E.g. web container linked to a db container, we don't want to expose the db container

The syntax is to use the `--link` flag to link a source container (e.g. db) to provide information to a recipient container (e.g. web)

`docker run -d -P --name web --link db:db training/webapp python app.py`

