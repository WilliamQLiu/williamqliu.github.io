---
layout: post
title: Kafka
---


# {{ page.title }}

Notes from: https://kafka.apache.org/documentation/

## What is Kafka?

Apache Kafka is a distributed streaming platform.

A __streaming platform__ can:

* Publish and Subscribe to streams of records (similar to a message queue)
* Store streams of records in a fault-tolerant durable way (i.e. can continue to operate when portions break)
* Process streams of records as they occur

## Why use Kafka?

Kafka is usually built for two classes of applications:

* Building real-time streaming data pipelines that reliably get data between systems or applications
* Building real-time streaming applications that transform or react to the streams of data

## Kafka Concepts

* Kafka runs as a cluster on one or more servers that can span multiple datacenters
* The Kafka cluster stores streams of __records__ in categories called __topics__
* Each record has a key, a value, and a timestamp

## Kafka Core APIs

Kafka has four core APIs.

* __Producer API__ - allows an application to publish a stream of records to one or more Kafka topics
* __Consumer API__ - allows an application to subscribe to one or more topics and process the stream of
                     records produced to them
* __Streams API__ - allows an application to act as a __stream processor__, consuming an input stream from
                    one or more topics and producing an output stream to one or more output topics
                    (i.e. transforms input streams to output streams)
* __Connector API__ - allows building and running reusable producers or consumers that connect Kafka
                      topics to existing applications or data systems (e.g. connector to a relational database
                      might capture every change to a table)

## Topics and Logs

The core abstraction that Kafka provides for a stream of records is the __topic__.

* A topic is a category or feed name where records are published.
* Topics are always __multi-subscriber__, meaning a topic can have zero, one, or many consumers that subscribe to
* the data written to it.
* For each topic, the Kafka cluster maintains a partitioned log that might look like:

Partition 0   0 1 2 3 4 5 6 7 8 9 10 11 12
Partition 1   0 1 2 3 4 5 6 7 8 9
Partition 2   0 1 2 3 4 5 6 7 8 9 19 11 12

Each __partition__ is an ordered, immutable sequence of records that is continually appended to.
The records in the partitions are each assigned a sequential id number called the __offset__ that uniquely
identifies each record within the partition.
The Kafka cluster durably persists all published records, whether or not they have been consumed by using
a configurable retention period.

