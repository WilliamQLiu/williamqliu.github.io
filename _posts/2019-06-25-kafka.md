---
layout: post
title: Kafka
---


# {{ page.title }}

Notes from: https://kafka.apache.org/documentation/

## What is Kafka?

Apache Kafka is a distributed streaming platform.

A __streaming platform__ can:

* Publish and Subscribe to streams of records (similar to a message queue)
* Store streams of records in a fault-tolerant durable way (i.e. can continue to operate when portions break)
* Process streams of records as they occur

## Why use Kafka?

Kafka is usually built for two classes of applications:

* Building real-time streaming data pipelines that reliably get data between systems or applications
* Building real-time streaming applications that transform or react to the streams of data

## Kafka Concepts

* Kafka runs as a cluster on one or more servers that can span multiple datacenters
* The Kafka cluster stores streams of __records__ in categories called __topics__
* Each record has a key, a value, and a timestamp

## Kafka Tools

Kafka MirrorMaker - Copy files
Kafkacat - command line to test and debug; can produce, consume, list topics and partition information
Kafka Connect - Allow import/export of data (e.g. write to S3 kafka messages in JSON)

## Kafka Core APIs

Kafka has four core APIs.

* __Producer API__ - allows an application to publish a stream of records to one or more Kafka topics
* __Consumer API__ - allows an application to subscribe to one or more topics and process the stream of
                     records produced to them
* __Streams API__ - allows an application to act as a __stream processor__, consuming an input stream from
                    one or more topics and producing an output stream to one or more output topics
                    (i.e. transforms input streams to output streams)
* __Connector API__ - allows building and running reusable producers or consumers that connect Kafka
                      topics to existing applications or data systems (e.g. connector to a relational database
                      might capture every change to a table)

## Monitoring

For Kafka:

* Latency and Net I/O is important


## Topics

The core abstraction that Kafka provides for a stream of records is the __topic__.

* A topic is a category or feed name where records are published.
* Topics are always __multi-subscriber__, meaning a topic can have zero, one, or many consumers that subscribe to
* the data written to it.
* For each topic, the Kafka cluster maintains a partitioned log that might look like:

Example Topic:

    Partition 0   0 1 2 3 4 5 6 7 8 9 10 11 12
    Partition 1   0 1 2 3 4 5 6 7 8 9
    Partition 2   0 1 2 3 4 5 6 7 8 9 19 11 12

Each __partition__ is an ordered, immutable sequence of records that is continually appended to.
The records in the partitions are each assigned a sequential id number called the __offset__ that uniquely
identifies each record within the partition. Offsets start at 0. Offsets keep increasing and are __immutable__.
The Kafka cluster durably persists all published records, whether or not they have been consumed by using
a configurable retention period (default: 7 days)
Unless you specify a key, partitions are not evenly distributed; they're randomly distributed.

## Producers

__Producers__ are clients, usually applications that create a stream of messages. Data is written to disk
and replicated. Producers can wait for __acks__, which means it will wait for a number of acknowledgements before
confirming the successful delivery of a message.

Producers can specify __keys__ to indicated that a message will go to the same partition every time.
Producers send messages to Kafka __brokers__, which is able to intelligently replicate the data and elect a leader.

## Consumers

__Consumers__ read messages and keep track of the offset.
When multiple messages are being read, a __consumer group__ can be formed so that each consumer is reading a different
message (i.e. no conflicts between reading many messages).

## Clusters and Brokers

A Kafka __cluster__ is made up of many Kafka brokers. A Kafka __broker__ is a server that receives messages from the
producer, assigns offsets and stores the messages on disk. Brokers replicate data across brokers in order to
create __fault tolerance__.

One broker is automatically selected as the __controller__, so this broker assigns the partitions for each broker
as well as monitors other brokers for failures (so it can fail over).

You can set __replication__ across brokers, meaning data is replicated across many brokers. With replication,
each Topic and Partition has a __Leader__ and `N` __Replica__ brokers (`N` being your __replication factor__ setting).
For example:

    Broker 1
    Topic A - Partition 0 (Leader)
    Topic A - Partition 2 (Replica)

    Broker 2
    Topic A - Partition 2 (Leader)
    Topic A - Partition 1 (Replica)

    Broker 3
    Topic A - Partition 1 (Leader)
    Topic A - Partition 0 (Replica)

## Zookeeper

__Zookeeper__ helps keep consensus within a cluster, meaning all brokers know which broker is the Controller,
the brokers are aware of each other, and what partition is is the Leader. Kafka requires Zookeeper in order to run.
Since Zookeeper helps with __Leader Election__, we must have an odd number of Zookeeper servers to keep __quorum__.

In a production setting, you want multiple zookeepers to create an __ensemble__.

## Install Kafka and Zookeeper

You can either install kafka and zookeeper using binaries or with containers.
Installing the binary takes more time, but allows you to run our programs as a service
(e.g. `sudo service zookeeper start`, `sudo service kafka start`) by adding to `/etc/init.d/kafka` and `/etc/init.d/zookeeper`
The below is with containers:

Add Docker to Your Package Repository

    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

    sudo add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
       $(lsb_release -cs) \
       stable"

Update Packages and Install Docker

    sudo apt update

    sudo apt install -y docker-ce=18.06.1~ce~3-0~ubuntu

Add Your User to the Docker Group

    sudo usermod -a -G docker cloud_user

Install Docker Compose

    sudo -i
    curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
    chmod +x /usr/local/bin/docker-compose

Install Java

    sudo apt install -y default-jdk

Get the Kafka Binaries

    wget http://mirror.cogentco.com/pub/apache/kafka/2.2.0/kafka_2.12-2.2.0.tgz
    tar -xvf kafka_2.12-2.2.0.tgz

Create Your First Topic

    ./bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partitions 3 --replication-factor 1

Describe the Topic

    ./bin/kafka-topics.sh --zookeeper localhost:2181 --topic test --describe

### Important Locations

`./bin` is where the executables are (e.g. `./bin/kafka-topics.sh`)
`./config` is where the configurations are

## Kafka Bin Commands

There are a few Kafka commands and you can see the available options by not typing in any additional params or arguments.
For example `./bin/kafka-topics.sh` gives you:

    ./kafka-topics.sh
    Create, delete, describe, or change a topic.
    Option                                   Description
    ------                                   -----------
    --alter                                  Alter the number of partitions,
                                               replica assignment, and/or
                                               configuration for the topic.
    --config <String: name=value>            A topic configuration override for the
                                               topic being created or altered.The
                                               following is a list of valid
                                               configurations:
                                                 cleanup.policy
                                                 compression.type
                                                 delete.retention.ms
                                                 file.delete.delay.ms
                                                 flush.messages
                                                 flush.ms
                                                 follower.replication.throttled.
                                               replicas
                                                 index.interval.bytes
                                                 leader.replication.throttled.replicas
                                                 max.message.bytes
                                                 message.format.version
                                                 message.timestamp.difference.max.ms
                                                 message.timestamp.type
                                                 min.cleanable.dirty.ratio
                                                 min.compaction.lag.ms
                                                 min.insync.replicas
                                                 preallocate
                                                 retention.bytes
                                                 retention.ms
                                                 segment.bytes
                                                 segment.index.bytes
                                                 segment.jitter.ms
                                                 segment.ms
                                                 unclean.leader.election.enable
                                             See the Kafka documentation for full
                                               details on the topic configs.
    --create                                 Create a new topic.
    --delete                                 Delete a topic
    --delete-config <String: name>           A topic configuration override to be
                                               removed for an existing topic (see
                                               the list of configurations under the
                                               --config option).
    --describe                               List details for the given topics.
    --disable-rack-aware                     Disable rack aware replica assignment
    --force                                  Suppress console prompts
    --help                                   Print usage information.
    --if-exists                              if set when altering or deleting
                                               topics, the action will only execute
                                               if the topic exists
    --if-not-exists                          if set when creating topics, the
                                               action will only execute if the
                                               topic does not already exist
    --list                                   List all available topics.
    --partitions <Integer: # of partitions>  The number of partitions for the topic
                                               being created or altered (WARNING:
                                               If partitions are increased for a
                                               topic that has a key, the partition
                                               logic or ordering of the messages
                                               will be affected
    --replica-assignment <String:            A list of manual partition-to-broker
      broker_id_for_part1_replica1 :           assignments for the topic being
      broker_id_for_part1_replica2 ,           created or altered.
      broker_id_for_part2_replica1 :
      broker_id_for_part2_replica2 , ...>
    --replication-factor <Integer:           The replication factor for each
      replication factor>                      partition in the topic being created.
    --topic <String: topic>                  The topic to be create, alter or
                                               describe. Can also accept a regular
                                               expression except for --create option
    --topics-with-overrides                  if set when describing topics, only
                                               show topics that have overridden
                                               configs
    --unavailable-partitions                 if set when describing topics, only
                                               show partitions whose leader is not
                                               available
    --under-replicated-partitions            if set when describing topics, only
                                               show under replicated partitions
    --zookeeper <String: hosts>              REQUIRED: The connection string for
                                               the zookeeper connection in the form
                                               host:port. Multiple hosts can be
                                               given to allow fail-over.

Things to note:

* __ISR__ stands for __In Sync Replica__, which means that if a Partition Leader fails, then one of these
  In Sync Replicas can take over as Leader
* __Configs__ will show if this topic has a different set of configurations
* When specifying `--zookeeper`, you can specify one or all zookeepers (if all, use comma separated list)


